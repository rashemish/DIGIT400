<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        <link rel="stylesheet" href="style.css"/>
        <title>DIGIT 400: Zotero Research</title>
        <link rel="stylesheet" href="https://use.typekit.net/qrv4bla.css">
    </head>
    <body>
        <h1> DIGIT 400: Researching the Foes of Digital Media and Technology </h1>
        <header>
            <nav class="navbar">
                <ul>
                    <li><a href="index.html">HOME</a></li>
                    <li><a href="howto.html">HOW TO BE AN ETHICAL DESIGNER</a></li>
                    <li><a href="casestudies.html">DATA PRIVACY: IN REAL LIFE</a></li>
                </ul>
            </nav>
        </header>
        <h2>CASE STUDIES: DATA PRIVACY IN PRACTICE (OR NOT)</h2>
        <div class="content wrapper">'
            <div class="info-container">
                <h4>Case Study #1: Microsoft Azure</h4>
                <p>On February 1st, 2010, Microsoft renamed its former service “Windows Azure” as “Microsoft Azure” to indicate its capability to work as a public cloud platform.</p>
                <p>Azure is a cloud computing platform from Microsoft that provides a wide range of cloud services, such as computing, analytics, storage, and networking, to help businesses build, deploy, and manage applications. <a href="https://www.techtarget.com/searchcloudcomputing/definition/Windows-Azure">To understand how this platform works, read this article from TechTarget.</a></p>
                <p>Around 3 years ago, Microsoft decided to improve its artificial intelligence policies, this AI is integrated and powers Microsoft Azure. Before, this facial recognition tool was used by companies for identification purposes. However, any and all companies that want to use this tool or are actively using it must apply for such tools. This is to ensure said companies are following Microsoft’s AI ethics standards.</p>
                <p>The decision to repair Azure in the first place was due to some of its more controversial features that enabled companies to understand gender, age, emotion through facial recognition technology. An example is their custom neural voice technology, which they have restricted due to its ability to create synthetic voices that are identical to the original source. Data that powers tools such as this can be violated as it requires personal bio data. Finding a proper boundary where one understands how data can actually be helpful until it starts violating privacy is crucial, a boundary Microsoft has understood.</p>
                <p>Microsoft hasn’t removed their emotion recognition artificial intelligence entirely, as they still use this for their accessibility features (Seeing AI). <a href="https://www.theguardian.com/technology/2022/jun/22/microsoft-limits-access-to-facial-recognition-tool-in-ai-ethics-overhaul">Want to read up on this case? Read more about it here!</a></p>
            </div>
        </div>
        <footer>
            <span class="footer">DIGIT 400 ZOTERO RESEARCH © 2025 by Raashee Mishra is licensed under CC BY-SA 4.0 </span><img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg" alt="" style="max-width: 1em;max-height:1em;margin-left: .2em;"/><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg" alt="" style="max-width: 1em;max-height:1em;margin-left: .2em;"/><img src="https://mirrors.creativecommons.org/presskit/icons/sa.svg" alt="" style="max-width: 1em;max-height:1em;margin-left: .2em;"/>
        </footer>
    </body>
</html>